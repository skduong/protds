{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93473d19",
   "metadata": {},
   "source": [
    "# View Structure Subsequences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be56ca",
   "metadata": {},
   "source": [
    "#### Set file name of the dataset, and run this cell once to initialize the program.\n",
    "- Dataset columns should have \"ProteinID\" and \"PeptideSequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.sequence_viewer import *\n",
    "\n",
    "filename = 'labled proteins data set.csv' \n",
    "data = pd.read_csv(os.path.join(\"data\",filename)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804619d",
   "metadata": {},
   "source": [
    "#### Choose any ProteinID to view selected sequences\n",
    "- default color order is: red | yellow | blue | green | (repeated if there are more than 4 columns of intensities)\n",
    "- color is determined by the maximum value amoung those columns\n",
    "- if no numbers exist for the subsequence (only overnight digestion), it is colored cyan   \n",
    "\n",
    "#### Set custom colors by modifying the colors list\n",
    "- the last color is used when no value is present for any time\n",
    "- use hexidecimal color codes: https://www.color-hex.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e551ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteinID = 'P07339'\n",
    "colors = ['red', 'yellow', 'blue', 'green', 'cyan']\n",
    "\n",
    "getPepView(proteinID, data, colors=colors, table=True) #set table=False to hide the table preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174f286",
   "metadata": {},
   "source": [
    "# Get GRAVY Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d77ba",
   "metadata": {},
   "source": [
    "- By default, the program will assume that Table1, Table2, and the FASTA files are in the \"data\" folder\n",
    "    - these locations can be customized to specify other paths\n",
    "- Output will be saved in the same folder location as Table 1\n",
    "- Alternatively, the same results can be obtained by running gravy_diff.py in the scripts folder\n",
    "- Table1 and Table2 should have columns named \"ProteinID\" and \"PeptideSequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gravy_diff import *\n",
    "\n",
    "#set file names\n",
    "table1 = \"Table 1_Peptides sequence_human urine solution digestion .csv\"\n",
    "table2 = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fasta = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "table1Path = os.path.join(\"data\",table1)\n",
    "table2Path = os.path.join(\"data\", table2)\n",
    "fastaPath = os.path.join(\"data\", fasta)\n",
    "\n",
    "table1diff = getGRAVYdiffs(fastaPath, table1Path, table2Path)\n",
    "\n",
    "#append results to table2:\n",
    "data2 = pd.read_csv(table2Path)\n",
    "if \"ProteinID\" not in data2.columns: data2 = data2.rename(columns={\"PG.UniProtIds\": \"ProteinID\", \"Stripped.Sequence\": \"PeptideSequence\"})\n",
    "#handling isomers:\n",
    "table1diff[\"UPID\"] = [i.split(';')[0] for i in table1diff[\"ProteinID\"].values]\n",
    "data2[\"UPID\"] = [i.split(';')[0] for i in data2[\"ProteinID\"].values]\n",
    "\n",
    "subset = table1diff.drop_duplicates(\"UPID\")[[\"UPID\", \"ProteinSequence\", \"SequenceGRAVY\", \"GRAVYdifference\", \"GRAVYdifference2\"]]\n",
    "table2diff = pd.merge(data2,subset, on=[\"UPID\"], how='left')\n",
    "table2diff.drop('UPID', axis=1).to_csv(table2Path[:-4]+'_GRAVY.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a7abf",
   "metadata": {},
   "source": [
    "# Get PeptideSequence Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39f0e9",
   "metadata": {},
   "source": [
    "#### Set file and Fasta name and run this cell to get peptide distances from their overall center of mass\n",
    "- Initial dataset should include a \"ProteinID\" and \"PeptideSequence\" column\n",
    "- When completed, the results will be saved as csv files in the output folder\n",
    "- The output only keeps ProteinIDs that have results in Protein Data Bank\n",
    "- This process takes a long time to complete (some hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, peptidePercentage\n",
    "\n",
    "filename = \"labled proteins data set.csv\" #set file name\n",
    "fastaname = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\" #set fasta name\n",
    "#if the files are not in the \"data\" folder, replace \"data\" with the full path to that location\n",
    "fastapath = os.path.join(\"data\", fastaname)\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "df = pepPositions(process(data, fastapath))\n",
    "\n",
    "#Overnight Digestion:\n",
    "alltimes = pepCenterDist(peptidePercentage(gravyDiff(df)), True) \n",
    "alltimes[0].drop(\"PepMid\", axis=1).to_csv(os.path.join(\"output\",\"Overnight\"+filename))\n",
    "summary = pd.DataFrame(pd.unique(alltimes[0][\"ProteinID\"]), columns=[\"ProteinID\"])\n",
    "\n",
    "#Separate Times:\n",
    "times = ['1st 15min','2nd 15min', '3rd 15min', '4th 15min'] #change to match the data's column names\n",
    "df = df[~df['ProteinID'].isin(alltimes[1])]\n",
    "for i in times:\n",
    "    subset = pepCenterDist(peptidePercentage(gravyDiff(df[df[i].notna()])))\n",
    "    subset.drop([t for t in times if t!=i]+[\"PepMid\"], axis=1).to_csv(os.path.join(\"output\",i+filename))\n",
    "    subset.drop_duplicates(subset=['ProteinID'])\n",
    "    #summary table:\n",
    "    for col in ['GRAVYdifference', 'PeptidePercentage', 'MeanDistances', 'StdDistances']:\n",
    "        summary[i+col] = summary.ProteinID.map(dict(zip(subset[\"ProteinID\"], subset[col].values)))\n",
    "for col in ['GRAVYdifference', 'PeptidePercentage', 'MeanDistances', 'StdDistances']:\n",
    "    summary[\"Overnight\"+col] = summary.ProteinID.map(dict(zip(alltimes[0][\"ProteinID\"], alltimes[0][col].values)))\n",
    "summary.to_csv(os.path.join(\"output\",\"Summary\"+filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snowflakes)",
   "language": "python",
   "name": "snowflakes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
