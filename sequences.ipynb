{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93473d19",
   "metadata": {},
   "source": [
    "# View Structure Subsequences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be56ca",
   "metadata": {},
   "source": [
    "#### Set file name of the dataset, and run this cell once to initialize the program.\n",
    "- Dataset columns should have \"ProteinID\" and \"PeptideSequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4bb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.sequence_viewer import *\n",
    "\n",
    "filename = 'Peptides sequence_human urine solution digestion.csv' \n",
    "data = pd.read_csv(os.path.join(\"data\",filename)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804619d",
   "metadata": {},
   "source": [
    "#### Choose any ProteinID to view selected sequences\n",
    "- default color order is: purple | yellow | blue | green | (repeated if there are more than 4 columns of intensities)\n",
    "- color is determined by the maximum value amoung those columns\n",
    "- if no numbers exist for the subsequence (only overnight digestion), it is colored cyan \n",
    "- if no \"min\" columns exist, then all sequences will be highlighted in the first listed color\n",
    "\n",
    "#### Set custom colors by modifying the colors list\n",
    "- the last color is used when no value is present for any time\n",
    "- use hexidecimal color codes: https://www.color-hex.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e551ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteinID = 'P02768'\n",
    "colors = ['#A020F0', 'yellow', 'blue', 'green', 'cyan']\n",
    "\n",
    "getPepView(proteinID, data, colors=colors, table=True) #set table=False to hide the table preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174f286",
   "metadata": {},
   "source": [
    "# Get GRAVY Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d77ba",
   "metadata": {},
   "source": [
    "- By default, the program will assume that Table1, Table2, and the FASTA files are in the \"data\" folder\n",
    "    - these locations can be customized to specify other paths\n",
    "- Output will be saved in the same folder location as Table 1\n",
    "- Alternatively, the same results can be obtained by running gravy_diff.py in the scripts folder\n",
    "- Table1 and Table2 should have columns named \"ProteinID\" and \"PeptideSequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gravy_diff import *\n",
    "\n",
    "#set file names\n",
    "table1 = \"Table 1_Peptides sequence_human urine solution digestion .csv\"\n",
    "table2 = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fasta = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "table1Path = os.path.join(\"data\",table1)\n",
    "table2Path = os.path.join(\"data\", table2)\n",
    "fastaPath = os.path.join(\"data\", fasta)\n",
    "\n",
    "table1diff = getGRAVYdiffs(fastaPath, table1Path, table2Path)\n",
    "\n",
    "#append results to table2:\n",
    "data2 = pd.read_csv(table2Path)\n",
    "if \"ProteinID\" not in data2.columns: data2 = data2.rename(columns={\"PG.UniProtIds\": \"ProteinID\", \"Stripped.Sequence\": \"PeptideSequence\"})\n",
    "#handling isomers:\n",
    "table1diff[\"UPID\"] = [i.split(';')[0] for i in table1diff[\"ProteinID\"].values]\n",
    "data2[\"UPID\"] = [i.split(';')[0] for i in data2[\"ProteinID\"].values]\n",
    "\n",
    "subset = table1diff.drop_duplicates(\"UPID\")[[\"UPID\", \"ProteinSequence\", \"SequenceGRAVY\", \"GRAVYdifference\", \"GRAVYdifference2\"]]\n",
    "table2diff = pd.merge(data2,subset, on=[\"UPID\"], how='left')\n",
    "table2diff.drop('UPID', axis=1).to_csv(table2Path[:-4]+'_GRAVY.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee1624",
   "metadata": {},
   "source": [
    "# Get Peptide Sequence Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gravy_diff import *\n",
    "\n",
    "#set file names:\n",
    "filename = \"labled proteins data set.csv\" \n",
    "fasta = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder\n",
    "filepath = os.path.join(\"data\",filename) \n",
    "fastaPath = os.path.join(\"data\", fasta)\n",
    "\n",
    "data = pd.read_csv(filepath)\n",
    "if \"ProteinSequence\" not in data.columns or \"PeptideSequence\" not in data.columns:\n",
    "    data = process(data, fastaPath)\n",
    "data = peptidePercentage(data)\n",
    "data.to_csv(os.path.join(\"output\", filename[:-4])+\"_Percentage.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a7abf",
   "metadata": {},
   "source": [
    "# Get PeptideSequence Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39f0e9",
   "metadata": {},
   "source": [
    "#### Set file and Fasta name and run this cell to get peptide distances from their overall center of mass\n",
    "- Initial dataset should include a \"ProteinID\" and \"PeptideSequence\" column\n",
    "- When completed, the results will be saved as csv files in the output folder\n",
    "- The output only keeps ProteinIDs that have results in Protein Data Bank\n",
    "- This process takes a long time to complete (some hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, peptidePercentage\n",
    "\n",
    "filename = \"labled proteins data set.csv\" #set file name\n",
    "fastaname = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\" #set fasta name\n",
    "\n",
    "#if the files are not in the \"data\" folder, replace \"data\" with the full path to that location\n",
    "fastapath = os.path.join(\"data\", fastaname)\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "\n",
    "df = pepPositions(process(pd.read_csv(filepath), fastapath))\n",
    "times = ['1st 15min','2nd 15min', '3rd 15min', '4th 15min', 'OvernightDigestion']#change to match the data's column names\n",
    "try:\n",
    "    getCenterDistByTime(filename, df, times)\n",
    "except TypeError:\n",
    "    invalid = [i[0] for i in proteins.items() if i[1].structures==None]\n",
    "    for i in invalid: del proteins[i]\n",
    "    getCenterDistByTime(filename, df, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd5434",
   "metadata": {},
   "source": [
    "# SVD Plane\n",
    "Find a plane that minimizes the total perpendicular distance from the points to the plane\n",
    "- A total least squares problem solved with Singular Value Decompostion\n",
    "- Run this cell to get the distances from each sequence to their plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, filterSequences\n",
    "\n",
    "#set names for the data and fasta files\n",
    "filename = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fastaname = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "fastapath = os.path.join(\"data\", fastaname)\n",
    "\n",
    "#results:\n",
    "data2 = process(pd.read_csv(filepath), fastapath, \"PG.UniProtIds\", \"Stripped.Sequence\")\n",
    "filtered = filterSequences(data2)\n",
    "table2 = pepPositions(filtered[0])\n",
    "try:\n",
    "    planeDists = pepPlaneDist(table2)\n",
    "except TypeError:\n",
    "    invalid = [i[0] for i in proteins.items() if i[1].structures==None]\n",
    "    for i in invalid: del proteins[i]\n",
    "    planeDists = pepPlaneDist(table2, True)\n",
    "\n",
    "planeDists.drop(\"PepMid\", axis=1).to_csv(os.path.join(\"output\", filename[:-4]+'_Plane.csv'))\n",
    "filtered[1].to_csv(os.path.join(\"filtered\", filename[:-4]+'_Plane_Excluded.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa925b1",
   "metadata": {},
   "source": [
    "# SVD Plane Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell once for initializations \n",
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, filterSequences\n",
    "from ipywidgets import *\n",
    "#%matplotlib notebook #for JupyterNotebook\n",
    "\n",
    "#set names for the data and fasta files\n",
    "filename = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fastaname = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "fastapath = os.path.join(\"data\", fastaname)\n",
    "\n",
    "#results:\n",
    "data2 = process(pd.read_csv(filepath), fastapath, \"PG.UniProtIds\", \"Stripped.Sequence\")\n",
    "filtered = filterSequences(data2)\n",
    "df = pepPositions(filtered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protid = \"O00391\" #select a ProteinID of interest\n",
    "\n",
    "%matplotlib widget \n",
    "protgroup = (protid, df[[protid in i for i in df.ProteinID]])\n",
    "if searchPDB(protid, False, protgroup[1].ProteinSequence.values[0]) != False:\n",
    "    plotPlane(protgroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496cf6e",
   "metadata": {},
   "source": [
    "# Intensity Summaries\n",
    "Assumed file structures:\n",
    "- There are multiple data files corresponding to incubation times, each with the same naming convention, but starting with different times. Ex:\n",
    "    - \"5min incubation_Plane_GRAVY_Percentage.csv\"\n",
    "    - \"15min incubation_Plane_GRAVY_Percentage.csv\"\n",
    "    - \"24h incubation_Plane_GRAVY_Percentage.csv\"\n",
    "      \n",
    "      \n",
    "- \"Average intensity\" is stored in one Excel file (intensityFile) with multiple sheets. Each sheet is similarly named, but starting with different times. Ex:\n",
    "    - \"5min incubation\"\n",
    "    - \"15min incubation\"\n",
    "    - \"24h incubation\"\n",
    "      \n",
    "       \n",
    "- Please make sure the times are named consistantly between the sheets and files (set in the times list)  \n",
    "  \n",
    "  \n",
    "- filename and intensitySheetName is the name following the times, including any spaces  \n",
    "  \n",
    "Results (time incubation_summary.csv) will be saved in the \"output\" folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.gravy_diff import intensitySummary\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"data\" #set location of the data files\n",
    "#set file names:\n",
    "classificationFile = \"Protein classification.xlsx\"\n",
    "intensityFile = \"Protein intensity.xlsx\" \n",
    "\n",
    "times = [\"5min\", \"15min\", \"30min\", \"24h\"] #set to match begining of file names\n",
    "intensitySheetName = \" incubation\" #name of sheets for intensityFile\n",
    "filename = \" incubation_Plane_GRAVY_Percentage.csv\"  #name of data to be summarized\n",
    "\n",
    "#Processing:\n",
    "classes = pd.read_excel(os.path.join(path, classificationFile), sheet_name = None)\n",
    "intensities = pd.read_excel(os.path.join(path, intensityFile), sheet_name = None)\n",
    "allclasses = pd.concat([df for df in classes.values()], ignore_index=True)\n",
    "classdict = dict(zip(allclasses['PG.UniProtIds'], allclasses.kmean_kernal))\n",
    "\n",
    "for i in times:\n",
    "    data = pd.read_csv(os.path.join(\"data\", i+filename))\n",
    "    intensitySummary(classdict, intensities[i+intensitySheetName], data).to_csv(os.path.join(\"output\", i+\" incubation_summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d69a51",
   "metadata": {},
   "source": [
    "### After the summaries are saved to the output folder, these following cells can be ran for correlation and trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de7492",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlations:\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "times = [\"5min\", \"15min\", \"30min\", \"24h\"]\n",
    "filename = \" incubation_summary.csv\"\n",
    "\n",
    "cols = ['SequenceGRAVY', 'GRAVYdifference','PeptidePercentage', 'Average Intensity','Average DistanceToPlane']\n",
    "\n",
    "for i in times:\n",
    "    file = i+filename\n",
    "    data = pd.read_csv(os.path.join(\"output\", file))\n",
    "    \n",
    "    print(f\"TIME = {i}\",'\\n', \"correlation:\")\n",
    "    #correlation and heatmaps\n",
    "    display(data[cols].corr())\n",
    "    sns.heatmap(data[cols].corr(), cmap='coolwarm', vmax=1.0, vmin=-1.0 )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed024350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trends: line correlations are saved in trend_dist_intensity.csv in the output folder\n",
    "# (After running this cell once, line plots can be generated in the following cell)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce \n",
    "\n",
    "times = [\"5min\", \"15min\", \"30min\", \"24h\"]\n",
    "filename = \" incubation_summary.csv\"\n",
    "files = [pd.read_csv(os.path.join(\"output\", i+filename))[['ProteinID', 'Average Intensity','Average DistanceToPlane']] for i in times]\n",
    "\n",
    "def relabelIDs (ids1, ids2): \n",
    "    labs = []\n",
    "    for i in ids2:\n",
    "        add = True\n",
    "        for j in ids1:\n",
    "            if i in j.split(\";\"): \n",
    "                labs+= [j]\n",
    "                add = False\n",
    "                break\n",
    "        if add: labs +=[i]\n",
    "    return labs\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    files[i].ProteinID = relabelIDs(files[i-1].ProteinID, files[i].ProteinID)\n",
    "\n",
    "distances = [df[[\"ProteinID\", \"Average DistanceToPlane\"]] for df in files]\n",
    "intensities = [df[[\"ProteinID\", \"Average Intensity\"]] for df in files]\n",
    "dists = reduce(lambda  left,right: pd.merge(left,right,on=['ProteinID'], how='outer'), distances)\n",
    "intens = reduce(lambda  left,right: pd.merge(left,right,on=['ProteinID'], how='outer'), intensities)\n",
    "dists.columns = [\"ProteinID\"]+times\n",
    "intens.columns = [\"ProteinID\"]+times\n",
    "\n",
    "#correlations\n",
    "df = pd.concat([dists, intens[intens.columns[1:]]], keys=['Avg DistanceToPlane','Avg Intensity'], axis=1)\n",
    "df[\"Correlation\"] = [round(pd.DataFrame([p[1:5],p[5:9]]).T.corr()[0][1], 5) for p in df.values]\n",
    "df.loc[~df['Correlation'].between(-1, 1, inclusive=\"both\"), \"Correlation\"] = None\n",
    "#classes\n",
    "pat = r'({})'.format('|'.join(classdict.keys()))\n",
    "extracted = df[df.columns[0]].str.extract(pat, expand=False).dropna()\n",
    "df['Classification'] = extracted.apply(lambda x: classdict[x]).reindex(df.index)\n",
    "\n",
    "df.to_csv(os.path.join(\"output\", \"trend_dist_intensity.csv\"), index=False)\n",
    "df.columns = list(df.columns.droplevel())[:-2]+[\"Correlation\", \"Classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Plots\n",
    "id = \"O00391\" #select a ProteinID\n",
    "\n",
    "selection = df[df[\"ProteinID\"]==id]\n",
    "print(\"Avg Distance:\")\n",
    "selection.iloc[:, 1:5].T.plot.line(legend=False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Avg Intensity:\")\n",
    "selection.iloc[:, 5:9].T.plot.line(legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1fea2",
   "metadata": {},
   "source": [
    "# Plane 1:\n",
    "\"Use the sequence in table 2 to define plane 1, calculate the distance of each sequenced peptide to this plane. (The sequence with the highest intensity at 1st 15min should on this plane.) ... the distance of the other sequences to this plane should be minimum.  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, filterSequences\n",
    "\n",
    "#set names for the data and fasta files\n",
    "filename = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fastaname = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "filepath = os.path.join(\"data\", filename)\n",
    "fastapath = os.path.join(\"data\", fastaname)\n",
    "\n",
    "#results:\n",
    "data2 = process(pd.read_csv(filepath), fastapath, \"PG.UniProtIds\", \"Stripped.Sequence\")\n",
    "filtered = filterSequences(data2)\n",
    "table2 = pepPositions(filtered[0])\n",
    "try:\n",
    "    planeDists = pepPlaneDist(table2, True).rename(columns={\"DistanceToPlane\": \"DistanceToPlane1\"})\n",
    "except TypeError:\n",
    "    invalid = [i[0] for i in proteins.items() if i[1].structures==None]\n",
    "    for i in invalid: del proteins[i]\n",
    "    planeDists = pepPlaneDist(table2, True).rename(columns={\"DistanceToPlane\": \"DistanceToPlane1\"})\n",
    "\n",
    "planeDists.drop(\"PepMid\", axis=1).to_csv(os.path.join(\"output\", filename[:-4]+'_Plane1.csv'))\n",
    "filtered[1].to_csv(os.path.join(\"filtered\", filename[:-4]+'_Plane1_Excluded.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527feeb2",
   "metadata": {},
   "source": [
    "### Angle between Plane1 and Plane2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = \"Table 1_Peptides sequence_human urine solution digestion .csv\" #used for plane2\n",
    "table1Path = os.path.join(\"data\", table1)\n",
    "    \n",
    "#table1-table2 sequences:\n",
    "data1 = pepPositions(filterSequences(process(pd.read_csv(table1Path), fastapath))[0])\n",
    "data1[\"UPID\"] = [i.split(';')[0] for i in data1[\"ProteinID\"].values]\n",
    "data2[\"UPID\"] = [i.split(';')[0] for i in data2[\"ProteinID\"].values]\n",
    "data1Minus2 = pd.merge(data1, data2, on=[\"UPID\", \"PeptideSequence\"], how=\"outer\", suffixes=('','_2'), indicator=True).query('_merge==\"left_only\"')[data1.columns]\n",
    "\n",
    "try:\n",
    "    angles = getAngles(planeDists, data1Minus2)\n",
    "except TypeError:\n",
    "    invalid = [i[0] for i in proteins.items() if i[1].structures==None]\n",
    "    for i in invalid: del proteins[i]\n",
    "    angles = getAngles(planeDists, data1Minus2)\n",
    "    \n",
    "angles.drop(\"PepMid\", axis=1).to_csv(os.path.join(\"output\", filename[:-4]+'_Plane1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3389a66",
   "metadata": {},
   "source": [
    "# Plane 2: \n",
    "\"For each protein in table 1 (human urine solution digestion), after removing the peptides sequences found in table 2, use the left sequences to define plane 2, calculate the distance of each sequenced peptide to this plane. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protds.peptide_distances import *\n",
    "from scripts.gravy_diff import process, pepPositions, filterSequences\n",
    "\n",
    "#set file names\n",
    "table1 = \"Table 1_Peptides sequence_human urine solution digestion .csv\"\n",
    "table2 = \"Table 2_20211204_HUVariousDigestionTime_pr_matrix.csv\"\n",
    "fasta = \"uniprot-human+taxonomy__Homo+sapiens+(Human)+[9606]_-filtered-revi--.fasta\"\n",
    "\n",
    "#replace \"data\" with a custom path if the files are located in another folder (in quotations)\n",
    "table1Path = os.path.join(\"data\",table1)\n",
    "table2Path = os.path.join(\"data\", table2)\n",
    "fastaPath = os.path.join(\"data\", fasta)\n",
    "\n",
    "#table1-table2 sequences:\n",
    "data1 = pepPositions(process(pd.read_csv(table1Path), fastaPath))\n",
    "data2 = pd.read_csv(table2Path) \n",
    "if \"ProteinID\" not in data2.columns: data2 = data2.rename(columns={\"PG.UniProtIds\": \"ProteinID\", \"Stripped.Sequence\": \"PeptideSequence\"})\n",
    "data1[\"UPID\"] = [i.split(';')[0] for i in data1[\"ProteinID\"].values]\n",
    "data2[\"UPID\"] = [i.split(';')[0] for i in data2[\"ProteinID\"].values]\n",
    "\n",
    "df = pd.merge(data1, data2, on=[\"UPID\", \"PeptideSequence\"], how=\"outer\", suffixes=('','_2'), indicator=True).query('_merge==\"left_only\"')[data1.columns]\n",
    "filtered = filterSequences(df)\n",
    "try:\n",
    "    diffdist = pepPlaneDist(filtered[0], False).drop([\"PepMid\", \"UPID\"], axis=1).rename(columns={\"DistanceToPlane\": \"DistanceToPlane2\"})\n",
    "except TypeError:\n",
    "    invalid = [i[0] for i in proteins.items() if i[1].structures==None]\n",
    "    for i in invalid: del proteins[i]\n",
    "    diffdist = pepPlaneDist(filtered[0], False).drop([\"PepMid\", \"UPID\"], axis=1).rename(columns={\"DistanceToPlane\": \"DistanceToPlane2\"})\n",
    "\n",
    "diffdist.to_csv(os.path.join(\"output\", table1[:-4]+'_Plane2.csv'))\n",
    "filtered[1].to_csv(os.path.join(\"filtered\", table1[:-4]+'_Plane2_Excluded.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snowflakes)",
   "language": "python",
   "name": "snowflakes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
